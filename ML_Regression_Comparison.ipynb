{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Machine Learning Regression Comparison\n",
        "\n",
        "This notebook implements and compares different regression algorithms on housing price data:\n",
        "1. Random Forest Regressor\n",
        "2. XGBoost\n",
        "3. CatBoost\n",
        "4. Artificial Neural Network (Keras)\n",
        "5. Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlightgbm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlgb\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostRegressor\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense, Dropout\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"‚úì All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "print(f\"Training data shape: {train_df.shape}\")\n",
        "print(f\"Test data shape: {test_df.shape}\")\n",
        "\n",
        "# Separate target variable\n",
        "y = train_df['SalePrice']\n",
        "\n",
        "# Select numerical features excluding 'Id' and 'SalePrice'\n",
        "numerical_features = train_df.select_dtypes(include=np.number).columns.tolist()\n",
        "numerical_features = [feature for feature in numerical_features if feature not in ['Id', 'SalePrice']]\n",
        "\n",
        "# Prepare feature sets\n",
        "X = train_df[numerical_features].copy()\n",
        "X_test_full = test_df[numerical_features].copy()\n",
        "\n",
        "# Handle missing values - fill with mean\n",
        "for col in X.columns:\n",
        "    if X[col].isnull().sum() > 0:\n",
        "        mean_val = X[col].mean()\n",
        "        X[col] = X[col].fillna(mean_val)\n",
        "        X_test_full[col] = X_test_full[col].fillna(mean_val)\n",
        "\n",
        "print(f\"\\nFeatures selected: {len(numerical_features)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Split and Scale Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Scale features \n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Validation set size: {X_val.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train Models\n",
        "\n",
        "### 4.1 Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training Random Forest Regressor...\")\n",
        "\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=15,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "rf_pred_train = rf_model.predict(X_train)\n",
        "rf_pred_val = rf_model.predict(X_val)\n",
        "\n",
        "# Calculate metrics\n",
        "rf_train_rmse = np.sqrt(mean_squared_error(y_train, rf_pred_train))\n",
        "rf_val_rmse = np.sqrt(mean_squared_error(y_val, rf_pred_val))\n",
        "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
        "rf_val_r2 = r2_score(y_val, rf_pred_val)\n",
        "\n",
        "print(f\"\\n‚úì Random Forest Results:\")\n",
        "print(f\"  Train RMSE: ${rf_train_rmse:,.2f}\")\n",
        "print(f\"  Val RMSE: ${rf_val_rmse:,.2f}\")\n",
        "print(f\"  Train R¬≤: {rf_train_r2:.4f}\")\n",
        "print(f\"  Val R¬≤: {rf_val_r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training XGBoost...\")\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbosity=1\n",
        ")\n",
        "\n",
        "xgb_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# Predictions\n",
        "xgb_pred_train = xgb_model.predict(X_train)\n",
        "xgb_pred_val = xgb_model.predict(X_val)\n",
        "\n",
        "# Calculate metrics\n",
        "xgb_train_rmse = np.sqrt(mean_squared_error(y_train, xgb_pred_train))\n",
        "xgb_val_rmse = np.sqrt(mean_squared_error(y_val, xgb_pred_val))\n",
        "xgb_train_r2 = r2_score(y_train, xgb_pred_train)\n",
        "xgb_val_r2 = r2_score(y_val, xgb_pred_val)\n",
        "\n",
        "print(f\"\\n‚úì XGBoost Results:\")\n",
        "print(f\"  Train RMSE: ${xgb_train_rmse:,.2f}\")\n",
        "print(f\"  Val RMSE: ${xgb_val_rmse:,.2f}\")\n",
        "print(f\"  Train R¬≤: {xgb_train_r2:.4f}\")\n",
        "print(f\"  Val R¬≤: {xgb_val_r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training CatBoost...\")\n",
        "\n",
        "cb_model = CatBoostRegressor(\n",
        "    iterations=500,\n",
        "    learning_rate=0.05,\n",
        "    depth=6,\n",
        "    eval_metric='RMSE',\n",
        "    random_seed=42,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "cb_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=(X_val, y_val),\n",
        "    early_stopping_rounds=50,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# Predictions\n",
        "cb_pred_train = cb_model.predict(X_train)\n",
        "cb_pred_val = cb_model.predict(X_val)\n",
        "\n",
        "# Calculate metrics\n",
        "cb_train_rmse = np.sqrt(mean_squared_error(y_train, cb_pred_train))\n",
        "cb_val_rmse = np.sqrt(mean_squared_error(y_val, cb_pred_val))\n",
        "cb_train_r2 = r2_score(y_train, cb_pred_train)\n",
        "cb_val_r2 = r2_score(y_val, cb_pred_val)\n",
        "\n",
        "print(f\"\\n‚úì CatBoost Results:\")\n",
        "print(f\"  Train RMSE: ${cb_train_rmse:,.2f}\")\n",
        "print(f\"  Val RMSE: ${cb_val_rmse:,.2f}\")\n",
        "print(f\"  Train R¬≤: {cb_train_r2:.4f}\")\n",
        "print(f\"  Val R¬≤: {cb_val_r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Artificial Neural Network (Keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training Keras ANN...\")\n",
        "\n",
        "# Build model\n",
        "ann_model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "ann_model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "# Train\n",
        "history = ann_model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Predictions\n",
        "ann_pred_train = ann_model.predict(X_train_scaled).flatten()\n",
        "ann_pred_val = ann_model.predict(X_val_scaled).flatten()\n",
        "\n",
        "# Calculate metrics\n",
        "ann_train_rmse = np.sqrt(mean_squared_error(y_train, ann_pred_train))\n",
        "ann_val_rmse = np.sqrt(mean_squared_error(y_val, ann_pred_val))\n",
        "ann_train_r2 = r2_score(y_train, ann_pred_train)\n",
        "ann_val_r2 = r2_score(y_val, ann_pred_val)\n",
        "\n",
        "print(f\"\\n‚úì Keras ANN Results:\")\n",
        "print(f\"  Train RMSE: ${ann_train_rmse:,.2f}\")\n",
        "print(f\"  Val RMSE: ${ann_val_rmse:,.2f}\")\n",
        "print(f\"  Train R¬≤: {ann_train_r2:.4f}\")\n",
        "print(f\"  Val R¬≤: {ann_val_r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training Linear Regression...\")\n",
        "\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "lr_pred_train = lr_model.predict(X_train)\n",
        "lr_pred_val = lr_model.predict(X_val)\n",
        "\n",
        "# Calculate metrics\n",
        "lr_train_rmse = np.sqrt(mean_squared_error(y_train, lr_pred_train))\n",
        "lr_val_rmse = np.sqrt(mean_squared_error(y_val, lr_pred_val))\n",
        "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
        "lr_val_r2 = r2_score(y_val, lr_pred_val)\n",
        "\n",
        "print(f\"\\n‚úì Linear Regression Results:\")\n",
        "print(f\"  Train RMSE: ${lr_train_rmse:,.2f}\")\n",
        "print(f\"  Val RMSE: ${lr_val_rmse:,.2f}\")\n",
        "print(f\"  Train R¬≤: {lr_train_r2:.4f}\")\n",
        "print(f\"  Val R¬≤: {lr_val_r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison DataFrame\n",
        "comparison_data = [\n",
        "    {\n",
        "        'Model': 'Random Forest',\n",
        "        'Train RMSE': rf_train_rmse,\n",
        "        'Val RMSE': rf_val_rmse,\n",
        "        'Train MAE': mean_absolute_error(y_train, rf_pred_train),\n",
        "        'Val MAE': mean_absolute_error(y_val, rf_pred_val),\n",
        "        'Train R2': rf_train_r2,\n",
        "        'Val R2': rf_val_r2\n",
        "    },\n",
        "    {\n",
        "        'Model': 'XGBoost',\n",
        "        'Train RMSE': xgb_train_rmse,\n",
        "        'Val RMSE': xgb_val_rmse,\n",
        "        'Train MAE': mean_absolute_error(y_train, xgb_pred_train),\n",
        "        'Val MAE': mean_absolute_error(y_val, xgb_pred_val),\n",
        "        'Train R2': xgb_train_r2,\n",
        "        'Val R2': xgb_val_r2\n",
        "    },\n",
        "    {\n",
        "        'Model': 'CatBoost',\n",
        "        'Train RMSE': cb_train_rmse,\n",
        "        'Val RMSE': cb_val_rmse,\n",
        "        'Train MAE': mean_absolute_error(y_train, cb_pred_train),\n",
        "        'Val MAE': mean_absolute_error(y_val, cb_pred_val),\n",
        "        'Train R2': cb_train_r2,\n",
        "        'Val R2': cb_val_r2\n",
        "    },\n",
        "    {\n",
        "        'Model': 'Keras ANN',\n",
        "        'Train RMSE': ann_train_rmse,\n",
        "        'Val RMSE': ann_val_rmse,\n",
        "        'Train MAE': mean_absolute_error(y_train, ann_pred_train),\n",
        "        'Val MAE': mean_absolute_error(y_val, ann_pred_val),\n",
        "        'Train R2': ann_train_r2,\n",
        "        'Val R2': ann_val_r2\n",
        "    },\n",
        "    {\n",
        "        'Model': 'Linear Regression',\n",
        "        'Train RMSE': lr_train_rmse,\n",
        "        'Val RMSE': lr_val_rmse,\n",
        "        'Train MAE': mean_absolute_error(y_train, lr_pred_train),\n",
        "        'Val MAE': mean_absolute_error(y_val, lr_pred_val),\n",
        "        'Train R2': lr_train_r2,\n",
        "        'Val R2': lr_val_r2\n",
        "    }\n",
        "]\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "df_comparison = df_comparison.sort_values('Val RMSE')\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL COMPARISON RESULTS\")\n",
        "print(\"=\"*80)\n",
        "print(df_comparison.to_string(index=False))\n",
        "\n",
        "# Find best model\n",
        "best_model_idx = df_comparison['Val RMSE'].idxmin()\n",
        "best_model = df_comparison.loc[best_model_idx, 'Model']\n",
        "best_rmse = df_comparison.loc[best_model_idx, 'Val RMSE']\n",
        "best_r2 = df_comparison.loc[best_model_idx, 'Val R2']\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"üèÜ BEST MODEL: {best_model}\")\n",
        "print(f\"   Validation RMSE: ${best_rmse:,.2f}\")\n",
        "print(f\"   Validation R¬≤ Score: {best_r2:.4f}\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Visualize Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot 1: RMSE comparison\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='Model', y='Val RMSE', data=df_comparison, palette='viridis')\n",
        "plt.title('Validation RMSE (Lower is Better)')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('RMSE ($)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Feature Importance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print top 10 features for each model\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TOP 10 MOST IMPORTANT FEATURES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "models_dict = {\n",
        "    'Random Forest': rf_model,\n",
        "    'XGBoost': xgb_model,\n",
        "    'CatBoost': cb_model\n",
        "}\n",
        "\n",
        "for model_name, model in models_dict.items():\n",
        "    importance = model.feature_importances_\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': numerical_features,\n",
        "        'Importance': importance\n",
        "    }).sort_values('Importance', ascending=False).head(10)\n",
        "    \n",
        "    print(f\"\\n{model_name}:\")\n",
        "    for i, row in importance_df.iterrows():\n",
        "        print(f\"  {row['Feature']:30s}: {row['Importance']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Summary Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display nice summary table\n",
        "summary_df = df_comparison.copy()\n",
        "summary_df['Val RMSE'] = summary_df['Val RMSE'].apply(lambda x: f\"${x:,.2f}\")\n",
        "summary_df['Train RMSE'] = summary_df['Train RMSE'].apply(lambda x: f\"${x:,.2f}\")\n",
        "summary_df['Val MAE'] = summary_df['Val MAE'].apply(lambda x: f\"${x:,.2f}\")\n",
        "summary_df['Train MAE'] = summary_df['Train MAE'].apply(lambda x: f\"${x:,.2f}\")\n",
        "summary_df['Val R2'] = summary_df['Val R2'].apply(lambda x: f\"{x:.4f}\")\n",
        "summary_df['Train R2'] = summary_df['Train R2'].apply(lambda x: f\"{x:.4f}\")\n",
        "print(summary_df)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
