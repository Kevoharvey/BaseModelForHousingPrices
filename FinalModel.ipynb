{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kevoharvey/BaseModelForHousingPrices/blob/main/FinalModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQUC4o_MO_Iq"
      },
      "source": [
        "# Machine Learning Regression Comparison\n",
        "## Comparing Random Forest, ANN, XGBoost, and CatBoost\n",
        "\n",
        "This notebook implements and compares different regression algorithms on housing price data:\n",
        "1. Random Forest Regressor\n",
        "2. XGBoost\n",
        "3. Artificial Neural Network (Keras)\n",
        "4. Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKg9y5C3O_Ix"
      },
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0HOwFErO_Iy",
        "outputId": "e5cb1f15-c1de-4f22-d901-81d163ff7761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error , accuracy_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCxw_-pXO_I0"
      },
      "source": [
        "## 2. Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "xD7Cs9ZfO_I0",
        "outputId": "3c4aacea-a869-4c29-8c5d-d835c5fbea40"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3145496989.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training data shape: {train_df.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
          ]
        }
      ],
      "source": [
        "# Load the datasets\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "print(f\"Training data shape: {train_df.shape}\")\n",
        "print(f\"Test data shape: {test_df.shape}\")\n",
        "\n",
        "# Separate target variable\n",
        "y = train_df['SalePrice']\n",
        "\n",
        "# Select numerical features excluding 'Id' and 'SalePrice'\n",
        "numerical_features = train_df.select_dtypes(include=np.number).columns.tolist()\n",
        "numerical_features = [feature for feature in numerical_features if feature not in ['Id', 'SalePrice']]\n",
        "\n",
        "# Prepare feature sets\n",
        "X = train_df[numerical_features].copy()\n",
        "X_test_full = test_df[numerical_features].copy()\n",
        "\n",
        "# Handle missing values - fill with median\n",
        "for col in X.columns:\n",
        "    if X[col].isnull().sum() > 0:\n",
        "        median_val = X[col].median()\n",
        "        X[col] = X[col].fillna(median_val)\n",
        "        X_test_full[col] = X_test_full[col].fillna(median_val)\n",
        "\n",
        "print(f\"\\nFeatures selected: {len(numerical_features)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Outliers"
      ],
      "metadata": {
        "id": "JLAGLsW6tF7a"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boDJzR5oO_I1"
      },
      "source": [
        "## 3. Split and Scale Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jFp2a-yO_I1"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Validation set size: {X_val.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBz9ffR9O_I2"
      },
      "source": [
        "## 4. Train Models\n",
        "\n",
        "### 4.1 Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZHM0dtdO_I2"
      },
      "outputs": [],
      "source": [
        "print(\"Training Random Forest Regressor...\")\n",
        "\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=15,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "rf_pred_train = rf_model.predict(X_train)\n",
        "rf_pred_val = rf_model.predict(X_val)\n",
        "\n",
        "# Calculate metrics\n",
        "rf_train_rmse = np.sqrt(mean_squared_error(y_train, rf_pred_train))\n",
        "rf_val_rmse = np.sqrt(mean_squared_error(y_val, rf_pred_val))\n",
        "rf_train_r2 = r2_score(y_train, rf_pred_train)\n",
        "rf_val_r2 = r2_score(y_val, rf_pred_val)\n",
        "\n",
        "print(f\"\\n‚úì Random Forest Results:\")\n",
        "print(f\"  Train RMSE: ${rf_train_rmse:,.2f}\")\n",
        "print(f\"  Val RMSE: ${rf_val_rmse:,.2f}\")\n",
        "print(f\"  Train R¬≤: {rf_train_r2:.4f}\")\n",
        "print(f\"  Val R¬≤: {rf_val_r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VuBY8oSO_I2"
      },
      "source": [
        "### 4.2 XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgL7jl_yO_I3"
      },
      "outputs": [],
      "source": [
        "print(\"Training XGBoost...\")\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbosity=1\n",
        ")\n",
        "\n",
        "xgb_model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_val, y_val)],\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# Predictions\n",
        "xgb_pred_train = xgb_model.predict(X_train)\n",
        "xgb_pred_val = xgb_model.predict(X_val)\n",
        "\n",
        "# Calculate metrics\n",
        "xgb_train_rmse = np.sqrt(mean_squared_error(y_train, xgb_pred_train))\n",
        "xgb_val_rmse = np.sqrt(mean_squared_error(y_val, xgb_pred_val))\n",
        "xgb_train_r2 = r2_score(y_train, xgb_pred_train)\n",
        "xgb_val_r2 = r2_score(y_val, xgb_pred_val)\n",
        "\n",
        "print(f\"\\n‚úì XGBoost Results:\")\n",
        "print(f\"  Train RMSE: ${xgb_train_rmse:,.2f}\")\n",
        "print(f\"  Val RMSE: ${xgb_val_rmse:,.2f}\")\n",
        "print(f\"  Train R¬≤: {xgb_train_r2:.4f}\")\n",
        "print(f\"  Val R¬≤: {xgb_val_r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8ROiUSWO_I4"
      },
      "source": [
        "### 4.3 Artificial Neural Network (Keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqkbHp5yO_I4"
      },
      "outputs": [],
      "source": [
        "print(\"Training Keras ANN...\")\n",
        "\n",
        "# Build model\n",
        "ann_model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "ann_model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "# Train\n",
        "history = ann_model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    validation_data=(X_val_scaled, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Predictions\n",
        "ann_pred_train = ann_model.predict(X_train_scaled).flatten()\n",
        "ann_pred_val = ann_model.predict(X_val_scaled).flatten()\n",
        "\n",
        "# Calculate metrics\n",
        "ann_train_rmse = np.sqrt(mean_squared_error(y_train, ann_pred_train))\n",
        "ann_val_rmse = np.sqrt(mean_squared_error(y_val, ann_pred_val))\n",
        "ann_train_r2 = r2_score(y_train, ann_pred_train)\n",
        "ann_val_r2 = r2_score(y_val, ann_pred_val)\n",
        "\n",
        "print(f\"\\n‚úì Keras ANN Results:\")\n",
        "print(f\"  Train RMSE: ${ann_train_rmse:,.2f}\")\n",
        "print(f\"  Val RMSE: ${ann_val_rmse:,.2f}\")\n",
        "print(f\"  Train R¬≤: {ann_train_r2:.4f}\")\n",
        "print(f\"  Val R¬≤: {ann_val_r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUHGuVO8O_I5"
      },
      "source": [
        "### 4.4 Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDw_jZcgO_I5"
      },
      "outputs": [],
      "source": [
        "print(\"Training Linear Regression...\")\n",
        "\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "lr_pred_train = lr_model.predict(X_train)\n",
        "lr_pred_val = lr_model.predict(X_val)\n",
        "\n",
        "# Calculate metrics\n",
        "lr_train_rmse = np.sqrt(mean_squared_error(y_train, lr_pred_train))\n",
        "lr_val_rmse = np.sqrt(mean_squared_error(y_val, lr_pred_val))\n",
        "lr_train_r2 = r2_score(y_train, lr_pred_train)\n",
        "lr_val_r2 = r2_score(y_val, lr_pred_val)\n",
        "\n",
        "print(f\"\\n‚úì Linear Regression Results:\")\n",
        "print(f\"  Train RMSE: ${lr_train_rmse:,.2f}\")\n",
        "print(f\"  Val RMSE: ${lr_val_rmse:,.2f}\")\n",
        "print(f\"  Train R¬≤: {lr_train_r2:.4f}\")\n",
        "print(f\"  Val R¬≤: {lr_val_r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZgDFU44O_I6"
      },
      "source": [
        "## 5. Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YS5GQHHFO_I6"
      },
      "outputs": [],
      "source": [
        "# Create comparison DataFrame\n",
        "comparison_data = [\n",
        "    {\n",
        "        'Model': 'Random Forest',\n",
        "        'Train RMSE': rf_train_rmse,\n",
        "        'Val RMSE': rf_val_rmse,\n",
        "        'Train MAE': mean_absolute_error(y_train, rf_pred_train),\n",
        "        'Val MAE': mean_absolute_error(y_val, rf_pred_val),\n",
        "        'Train R2': rf_train_r2,\n",
        "        'Val R2': rf_val_r2\n",
        "    },\n",
        "    {\n",
        "        'Model': 'XGBoost',\n",
        "        'Train RMSE': xgb_train_rmse,\n",
        "        'Val RMSE': xgb_val_rmse,\n",
        "        'Train MAE': mean_absolute_error(y_train, xgb_pred_train),\n",
        "        'Val MAE': mean_absolute_error(y_val, xgb_pred_val),\n",
        "        'Train R2': xgb_train_r2,\n",
        "        'Val R2': xgb_val_r2\n",
        "    },\n",
        "    {\n",
        "        'Model': 'Keras ANN',\n",
        "        'Train RMSE': ann_train_rmse,\n",
        "        'Val RMSE': ann_val_rmse,\n",
        "        'Train MAE': mean_absolute_error(y_train, ann_pred_train),\n",
        "        'Val MAE': mean_absolute_error(y_val, ann_pred_val),\n",
        "        'Train R2': ann_train_r2,\n",
        "        'Val R2': ann_val_r2\n",
        "    },\n",
        "    {\n",
        "        'Model': 'Linear Regression',\n",
        "        'Train RMSE': lr_train_rmse,\n",
        "        'Val RMSE': lr_val_rmse,\n",
        "        'Train MAE': mean_absolute_error(y_train, lr_pred_train),\n",
        "        'Val MAE': mean_absolute_error(y_val, lr_pred_val),\n",
        "        'Train R2': lr_train_r2,\n",
        "        'Val R2': lr_val_r2\n",
        "    }\n",
        "]\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "df_comparison = df_comparison.sort_values('Val RMSE')\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL COMPARISON RESULTS\")\n",
        "print(\"=\"*80)\n",
        "print(df_comparison.to_string(index=False))\n",
        "\n",
        "# Find best model\n",
        "best_model_idx = df_comparison['Val RMSE'].idxmin()\n",
        "best_model = df_comparison.loc[best_model_idx, 'Model']\n",
        "best_rmse = df_comparison.loc[best_model_idx, 'Val RMSE']\n",
        "best_r2 = df_comparison.loc[best_model_idx, 'Val R2']\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"  BEST MODEL: {best_model}\")\n",
        "print(f\"   Validation RMSE: ${best_rmse:,.2f}\")\n",
        "print(f\"   Validation R-squared Score: {best_r2:.4f}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK9S-wSHO_I6"
      },
      "source": [
        "## 6. Visualize Model Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkajynxfO_I7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "\n",
        "def plot_learning_curve(estimator, title, X, y, cv=5, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring='neg_root_mean_squared_error')\n",
        "\n",
        "    train_scores_mean = -np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = -np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"RMSE\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.grid(True)\n",
        "    return plt\n",
        "\n",
        "# Set up the figure for multiple visualizations\n",
        "plt.figure(figsize=(20, 16))\n",
        "\n",
        "# 1. RMSE Comparison (Bar Plot)\n",
        "plt.subplot(3, 2, 1)\n",
        "sns.barplot(x='Model', y='Val RMSE', data=df_comparison, palette='viridis')\n",
        "plt.title('Validation RMSE Comparison (Lower is Better)')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('RMSE ($)')\n",
        "plt.xticks(rotation=45)\n",
        "for i, v in enumerate(df_comparison['Val RMSE']):\n",
        "    plt.text(i, v + 500, f\"${v:,.0f}\", ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 2. R2 Score Comparison (Bar Plot)\n",
        "plt.subplot(3, 2, 2)\n",
        "sns.barplot(x='Model', y='Val R2', data=df_comparison, palette='magma')\n",
        "plt.title('Validation R¬≤ Score (Higher is Better)')\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('R¬≤ Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylim(0, 1.1)\n",
        "for i, v in enumerate(df_comparison['Val R2']):\n",
        "    plt.text(i, v + 0.02, f\"{v:.4f}\", ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 3. XGBoost Training Performance Trend\n",
        "plt.subplot(3, 2, 3)\n",
        "try:\n",
        "    results = xgb_model.evals_result()\n",
        "    epochs = len(results['validation_0']['rmse'])\n",
        "    x_axis = range(0, epochs)\n",
        "    plt.plot(x_axis, results['validation_0']['rmse'], label='Validation RMSE', color='orange')\n",
        "    plt.legend()\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.title('XGBoost Performance Trend')\n",
        "    plt.grid(True)\n",
        "except Exception as e:\n",
        "    plt.text(0.5, 0.5, f'XGBoost evals not available: {e}', ha='center')\n",
        "\n",
        "# 4. Keras ANN Training History\n",
        "plt.subplot(3, 2, 4)\n",
        "try:\n",
        "    if 'history' in globals() and hasattr(history, 'history'):\n",
        "         plt.plot(history.history['loss'], label='Train Loss (MSE)')\n",
        "         plt.plot(history.history['val_loss'], label='Val Loss (MSE)')\n",
        "         plt.title('Keras ANN Model Loss')\n",
        "         plt.ylabel('Loss (MSE)')\n",
        "         plt.xlabel('Epoch')\n",
        "         plt.legend(loc='upper right')\n",
        "         plt.grid(True)\n",
        "    else:\n",
        "         plt.text(0.5, 0.5, 'Keras history not available', ha='center')\n",
        "except Exception as e:\n",
        "    plt.text(0.5, 0.5, f'Keras history error: {e}', ha='center')\n",
        "\n",
        "# 5. Learning Efficiency (Learning Curve for Best Model - XGBoost)\n",
        "plt.subplot(3, 2, 5)\n",
        "try:\n",
        "    plot_learning_curve(\n",
        "        xgb.XGBRegressor(n_estimators=50, max_depth=6, random_state=42, n_jobs=-1),\n",
        "        \"Learning Efficiency (XGBoost)\",\n",
        "        X_train_scaled, y_train, cv=3\n",
        "    )\n",
        "except Exception as e:\n",
        "    plt.text(0.5, 0.5, f'Error plotting learning curve: {str(e)}', ha='center')\n",
        "\n",
        "# 6. Performance Ranking\n",
        "plt.subplot(3, 2, 6)\n",
        "ranking_df = df_comparison.sort_values('Val RMSE', ascending=True)\n",
        "sns.pointplot(x='Val RMSE', y='Model', data=ranking_df, join=False, color='b')\n",
        "plt.title('Model Performance Ranking (Validation RMSE)')\n",
        "plt.xlabel('RMSE ($)')\n",
        "plt.grid(True, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nBWL2RJO_I8"
      },
      "source": [
        "## 8. Summary Table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbe5e782"
      },
      "outputs": [],
      "source": [
        "# Display nice summary table\n",
        "summary_df = df_comparison.copy()\n",
        "summary_df['Val RMSE'] = summary_df['Val RMSE'].apply(lambda x: f\"${x:,.2f}\")\n",
        "summary_df['Train RMSE'] = summary_df['Train RMSE'].apply(lambda x: f\"${x:,.2f}\")\n",
        "summary_df['Val MAE'] = summary_df['Val MAE'].apply(lambda x: f\"${x:,.2f}\")\n",
        "summary_df['Train MAE'] = summary_df['Train MAE'].apply(lambda x: f\"${x:,.2f}\")\n",
        "summary_df['Val R2'] = summary_df['Val R2'].apply(lambda x: f\"{x:.4f}\")\n",
        "summary_df['Train R2'] = summary_df['Train R2'].apply(lambda x: f\"{x:.4f}\")\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Style the dataframe\n",
        "styled_df = summary_df.style.set_properties(**{\n",
        "    'text-align': 'center',\n",
        "    'font-size': '12pt'\n",
        "}).set_table_styles([\n",
        "    {\n",
        "        'selector': 'th',\n",
        "        'props': [('font-size', '14pt'), ('font-weight', 'bold'), ('text-align', 'center')]\n",
        "    }\n",
        "])\n",
        "\n",
        "display(styled_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1182df15"
      },
      "outputs": [],
      "source": [
        "# Print top 10 features for each model\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TOP 10 MOST IMPORTANT FEATURES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "models_dict = {\n",
        "    'Random Forest': rf_model,\n",
        "    'XGBoost': xgb_model,\n",
        "}\n",
        "\n",
        "for model_name, model in models_dict.items():\n",
        "    importance = model.feature_importances_\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': numerical_features,\n",
        "        'Importance': importance\n",
        "    }).sort_values('Importance', ascending=False).head(10)\n",
        "\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    for i, row in importance_df.iterrows():\n",
        "        print(f\"  {row['Feature']:30s}: {row['Importance']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5549788b"
      },
      "source": [
        "## Extract Top 10 XGBoost Features\n",
        "\n",
        "### Subtask:\n",
        "Extract the names of the top 10 most important features from the previously trained XGBoost model's feature importances. This will fix the KeyError encountered before.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f3e6376"
      },
      "outputs": [],
      "source": [
        "top_10_xgb_features = importance_df['Feature'].tolist()\n",
        "print(f\"Top 10 XGBoost Features: {top_10_xgb_features}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d0e7073"
      },
      "outputs": [],
      "source": [
        "X_train_top10 = X_train[top_10_xgb_features]\n",
        "X_val_top10 = X_val[top_10_xgb_features]\n",
        "X_test_top10 = X_test_full[top_10_xgb_features]\n",
        "\n",
        "print(f\"X_train_top10 shape: {X_train_top10.shape}\")\n",
        "print(f\"X_val_top10 shape: {X_val_top10.shape}\")\n",
        "\n",
        "# Train XGBoost model on top 10 features\n",
        "xgb_top10 = XGBRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbosity=1\n",
        ")\n",
        "xgb_top10.fit(X_train_top10, y_train)\n",
        "\n",
        "# Make predictions\n",
        "xgb_top10_pred_train = xgb_top10.predict(X_train_top10)\n",
        "xgb_top10_pred_val = xgb_top10.predict(X_val_top10)\n",
        "\n",
        "# Evaluate model\n",
        "xgb_top10_train_rmse = np.sqrt(mean_squared_error(y_train, xgb_top10_pred_train))\n",
        "xgb_top10_val_rmse = np.sqrt(mean_squared_error(y_val, xgb_top10_pred_val))\n",
        "xgb_top10_train_r2 = r2_score(y_train, xgb_top10_pred_train)\n",
        "xgb_top10_val_r2 = r2_score(y_val, xgb_top10_pred_val)\n",
        "xgb_top10_train_mae = mean_absolute_error(y_train, xgb_top10_pred_train)\n",
        "xgb_top10_val_mae = mean_absolute_error(y_val, xgb_top10_pred_val)\n",
        "\n",
        "print(f\"\\nXGBoost Top 10 Features Results:\")\n",
        "print(f\"  Train RMSE: ${xgb_top10_train_rmse:,.2f}\")\n",
        "print(f\"  Val RMSE: ${xgb_top10_val_rmse:,.2f}\")\n",
        "print(f\"  Train R¬≤: {xgb_top10_train_r2:.4f}\")\n",
        "print(f\"  Val R¬≤: {xgb_top10_val_r2:.4f}\")\n",
        "print(f\"  Train MAE: ${xgb_top10_train_mae:,.2f}\")\n",
        "print(f\"  Val MAE: ${xgb_top10_val_mae:,.2f}\")\n",
        "\n",
        "# Make predictions on test set\n",
        "xgb_top10_pred_test = xgb_top10.predict(X_test_top10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b4586ff"
      },
      "outputs": [],
      "source": [
        "xgboost_top10_data = {\n",
        "    'Model': 'XGBoost (Top 10 Features)',\n",
        "    'Train RMSE': xgb_top10_train_rmse,\n",
        "    'Val RMSE': xgb_top10_val_rmse,\n",
        "    'Train MAE': mean_absolute_error(y_train, xgb_top10_pred_train),\n",
        "    'Val MAE': mean_absolute_error(y_val, xgb_top10_pred_val),\n",
        "    'Train R2': xgb_top10_train_r2,\n",
        "    'Val R2': xgb_top10_val_r2\n",
        "}\n",
        "\n",
        "df_comparison_top10 = pd.DataFrame([xgboost_top10_data])\n",
        "\n",
        "# Filter out the original XGBoost entry and append the new one for comparison\n",
        "df_comparison_updated = df_comparison[df_comparison['Model'] != 'XGBoost'].copy()\n",
        "df_comparison_updated = pd.concat([df_comparison_updated, df_comparison_top10], ignore_index=True)\n",
        "df_comparison_updated = df_comparison_updated.sort_values('Val RMSE').reset_index(drop=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"MODEL COMPARISON RESULTS (INCLUDING XGBoost Top 10 Features)\")\n",
        "print(\"=\"*80)\n",
        "print(df_comparison_updated.to_string(index=False))\n",
        "\n",
        "# Find best model from updated comparison\n",
        "best_model_idx_updated = df_comparison_updated['Val RMSE'].idxmin()\n",
        "best_model_updated = df_comparison_updated.loc[best_model_idx_updated, 'Model']\n",
        "best_rmse_updated = df_comparison_updated.loc[best_model_idx_updated, 'Val RMSE']\n",
        "best_r2_updated = df_comparison_updated.loc[best_model_idx_updated, 'Val R2']\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"  BEST MODEL: {best_model_updated}\")\n",
        "print(f\"   Validation RMSE: ${best_rmse_updated:,.2f}\")\n",
        "print(f\"   Validation R-squared Score: {best_r2_updated:.4f}\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradio interface\n",
        "import gradio as gr\n",
        "\n",
        "# Calculate average percentage error on validation set\n",
        "percentage_errors = np.abs((y_val -xgb_top10_pred_val) / y_val) * 100\n",
        "avg_percentage_error = np.mean(percentage_errors)\n",
        "avg_accuracy_percentage = 100 - avg_percentage_error\n",
        "\n",
        "# Prediction function\n",
        "def predict_house_price(*args):\n",
        "  # Create dataframe from user inputs\n",
        "  input_data = pd.DataFrame([args], columns=top_10_xgb_features)\n",
        "\n",
        "  # Make prediction\n",
        "  prediction = xgb_top10.predict(input_data)[0]\n",
        "\n",
        "  # Calculate prediction accuracy% using MAPE(Mean Absolute Percentage Error)\n",
        "  expected_error_percentage = (xgb_top10_val_mae / prediction) * 100\n",
        "  prediction_accuracy = 100 - expected_error_percentage\n",
        "\n",
        "  # Ensure accuracy is within reasonable bounds\n",
        "  prediction_accuracy = max(0, min(100, prediction_accuracy))\n",
        "\n",
        "  # Format the predicted price output with accuracy\n",
        "  price_output = f\"${prediction:,.2f}\\n\\nüéØ Prediction Accuracy: {prediction_accuracy:.1f}%\"\n",
        "\n",
        "  # Format detailed accuracy text\n",
        "  accuracy_text = f\"\"\"\n",
        "\n",
        "üéØ **This Prediction Accuracy:** {prediction_accuracy:.1f}%\n",
        "- Expected error range: ¬±${xgb_top10_val_mae:,.2f} (¬±{expected_error_percentage:.1f}%)\n",
        "- Predicted price range: ${prediction - xgb_top10_val_mae:,.2f} ‚Üí ${prediction + xgb_top10_val_mae:,.2f}\n",
        "\n",
        "‚úÖ **Confidence Level:** {\"HIGH\" if prediction_accuracy >= 90 else \"MEDIUM\" if prediction_accuracy >= 80 else \"MODERATE\"}\n",
        "\"\"\"\n",
        "  return price_output, accuracy_text\n"
      ],
      "metadata": {
        "id": "DQ1YvyrGnwIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create gradio interface\n",
        "\n",
        "#Feature name mapping for user-friendly display\n",
        "feature_labels = {\n",
        "    'OverallQual': '‚≠ê Overall Quality (1-10)',\n",
        "    'GarageCars': 'üöó Garage Capacity (Cars)',\n",
        "    'GrLivArea': 'üè† Living Area (sq ft)',\n",
        "    'BsmtFinSF1': 'üî® Finished Basement Area (sq ft)',\n",
        "    '2ndFlrSF': '‚¨ÜÔ∏è Second Floor Area (sq ft)',\n",
        "    'PoolArea': 'üèä Pool Area (sq ft)',\n",
        "    'Fireplaces': 'üî• Number of Fireplaces',\n",
        "    'TotalBsmtSF': 'üì¶ Total Basement Area (sq ft)',\n",
        "    'YearBuilt': 'üìÖ Year Built',\n",
        "    'KitchenAbvGr': 'üë®‚Äçüç≥ Kitchens Above Ground'\n",
        "}\n",
        "# Determine dataset for slider initialization\n",
        "slider_data = (X_train_top10)\n",
        "\n",
        "# Create sliders with friendly labels\n",
        "sliders = [\n",
        "    gr.Slider(\n",
        "        minimum=float(slider_data[f].min()),\n",
        "        maximum=float(slider_data[f].max()),\n",
        "        value=float(slider_data[f].median()),\n",
        "        label=feature_labels.get(f, f),\n",
        "        info=f\"Range: {slider_data[f].min():.0f} - {slider_data[f].max():.0f}\"\n",
        "    ) for f in top_10_xgb_features\n",
        "]\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Monochrome(), title=\"House Price Predictor\") as demo:\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "<div style=\"text-align: center;\">\n",
        "<h1 style=\"font-size: 50px; margin-bottom: 10px;\">House Price Prediction System üè°</h1>\n",
        "<h3 style=\"font-size: 24px; margin-top: 0;\">Powered by XGBoost Machine Learning Model</h3>\n",
        "</div>\n",
        "\"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"## House Features\")\n",
        "            # Render the sliders\n",
        "            for slider in sliders:\n",
        "                slider.render()\n",
        "\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"## üí∞ Prediction Results\")\n",
        "            predict_btn = gr.Button(\"Predict Price\", variant=\"primary\", size=\"lg\")\n",
        "            predicted_price = gr.Textbox(\"Predicted House Price & Accuracy\", interactive=False, lines=3)\n",
        "            accuracy_output = gr.Markdown(\"*Click 'Predict Price' to see detailed accuracy metrics*\")\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    ---\n",
        "    ### üìñ How to Use\n",
        "    Adjust sliders ‚Üí Predict ‚Üí Review accuracy\n",
        "    \"\"\")\n",
        "\n",
        "    # Connect prediction function\n",
        "    predict_btn.click(predict_house_price, inputs=sliders, outputs=[predicted_price, accuracy_output])\n"
      ],
      "metadata": {
        "id": "6BiqsjKpTJFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LAUNCH INTERFACE\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"LAUNCHING GRADIO INTERFACE...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "7Kv3Kus3x1UO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}